{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Routing PDF Queries Using Metadata (No Embeddings Needed)**\n",
        "This notebook is an extenstion of the Project 7 Step 2 DEMO code for classifying user queries to most relevant PDF pages using metadata stored, without depending on embeddings exclusively.\n",
        "\n"
      ],
      "metadata": {
        "id": "onhxlcVhA24b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 1) Setup & Imports -----------------------------------\n",
        "# Try to use either pypdf or PyPDF2 for text extraction.\n",
        "# (We keep both to increase the chance of extraction working\n",
        "#  across different environments like Colab vs. local.)\n",
        "\n",
        "import os, re, json, uuid\n",
        "from typing import List, Dict, Any\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Optional PDF backends\n",
        "try:\n",
        "    import pypdf\n",
        "    HAVE_PYPDF = True\n",
        "except Exception:\n",
        "    HAVE_PYPDF = False\n",
        "try:\n",
        "    import PyPDF2\n",
        "    HAVE_PYPDF2 = True\n",
        "except Exception:\n",
        "    HAVE_PYPDF2 = False\n",
        "\n",
        "DOC_TYPES = [\"pay_stub\", \"loan_form\", \"resume\", \"contract\", \"w2\", \"unknown\"]"
      ],
      "metadata": {
        "id": "gvBnjlMxVzb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 2) Load a Set of Documents ----------------------------\n",
        "# Tip: In Colab, your files may live under /content; when running here,\n",
        "# they might be under /mnt/data. We include both and pick existing files.\n",
        "\n",
        "FILES = [\n",
        "    \"/content/payslip-1752803610.pdf\",\n",
        "    \"/content/payslip-1752804713.pdf\",\n",
        "    \"/content/COE-Sample.pdf\",\n",
        "    \"/content/functionalsample.pdf\",\n",
        "    \"/content/SampleContract-Shuttle.pdf\",\n",
        "    \"/content/LenderFeesWorksheetNew.pdf\",\n",
        "]"
      ],
      "metadata": {
        "id": "v-pgjGN9Tk4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _extract_text_pypdf(path: str):\n",
        "    reader = pypdf.PdfReader(path)\n",
        "    return [(page.extract_text() or \"\") for page in reader.pages]\n",
        "\n",
        "def _extract_text_pypdf2(path: str):\n",
        "    reader = PyPDF2.PdfReader(path)\n",
        "    return [(page.extract_text() or \"\") for page in reader.pages]\n",
        "\n",
        "def extract_text_pages(path: str):\n",
        "    if HAVE_PYPDF:\n",
        "        try:\n",
        "            return _extract_text_pypdf(path)\n",
        "        except Exception:\n",
        "            pass\n",
        "    if HAVE_PYPDF2:\n",
        "        try:\n",
        "            return _extract_text_pypdf2(path)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return [\"\"]\n",
        "\n",
        "def year_from_text(t: str) -> str:\n",
        "    m = re.search(r\"(20\\d{2}|19\\d{2})\", t or \"\")\n",
        "    return m.group(1) if m else \"\""
      ],
      "metadata": {
        "id": "iqzU2lQbV1-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pdf_metadata_store(files: List[str]) -> List[Dict[str, Any]]:\n",
        "    store: List[Dict[str, Any]] = []\n",
        "    for path in files:\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        file_id = str(uuid.uuid4())\n",
        "        filename = os.path.basename(path)\n",
        "        pages = extract_text_pages(path)\n",
        "        for i, text in enumerate(pages):\n",
        "            store.append({\n",
        "                \"file_id\": file_id,\n",
        "                \"user_id\": \"xyz\",           # FIXED: don't reference an undefined variable\n",
        "                \"filename\": filename,\n",
        "                \"page_number\": i + 1,\n",
        "                \"year\": year_from_text(text),\n",
        "                \"text\": text or \"\",\n",
        "                \"doc_type\": None,\n",
        "            })\n",
        "    return store"
      ],
      "metadata": {
        "id": "A4vMRrUkV8N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 3) Classify the User Query ----------------------------\n",
        "\n",
        "def classify_query_llm(query: str) -> str:\n",
        "    q = (query or \"\").lower()\n",
        "    if any(k in q for k in [\"salary\", \"net pay\", \"paystub\", \"pay stub\", \"gross pay\", \"pay date\", \"monthly pay\", \"pay statement\"]):\n",
        "        return \"pay_stub\"\n",
        "    if any(k in q for k in [\"loan\", \"mortgage\", \"escrow\", \"origination\", \"title insurance\", \"fees worksheet\", \"closing costs\", \"lender\"]):\n",
        "        return \"loan_form\"\n",
        "    if any(k in q for k in [\"resume\", \"cv\", \"work experience\", \"employment history\"]):\n",
        "        return \"resume\"\n",
        "    if any(k in q for k in [\"contract\", \"agreement\", \"professional services\", \"terms of employment\", \"probationary\"]):\n",
        "        return \"contract\"\n",
        "    if \"w2\" in q or \"w-2\" in q or \"w2 form\" in q:\n",
        "        return \"w2\"\n",
        "    return \"unknown\""
      ],
      "metadata": {
        "id": "UGAWSoitV_Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- 4) Assign a doc_type to Each Page ---------------------\n",
        "\n",
        "def classify_doc_type_llm(text: str) -> str:\n",
        "    t = (text or \"\").lower()\n",
        "    if any(k in t for k in [\"payslip\", \"pay date\", \"net pay\", \"earnings\", \"this is system generated payslip\", \"working days\"]):\n",
        "        return \"pay_stub\"\n",
        "    if any(k in t for k in [\"fees worksheet\", \"loan program\", \"origination\", \"escrow fee\", \"hazard insurance premium\", \"daily interest charges\", \"lender's title insurance\"]):\n",
        "        return \"loan_form\"\n",
        "    if any(k in t for k in [\"functional resume\", \"career summary\", \"employment history\", \"education\", \"gpa (4.0 scale)\"]):\n",
        "        return \"resume\"\n",
        "    if any(k in t for k in [\"professional services agreement\", \"this agreement\", \"sample contract\", \"contract no.\", \"probationary\"]):\n",
        "        return \"contract\"\n",
        "    if \"w-2\" in t or \"form w-2\" in t:\n",
        "        return \"w2\"\n",
        "    return \"unknown\""
      ],
      "metadata": {
        "id": "oe6BYch5WBRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_doc_types(store: List[Dict[str, Any]]) -> None:\n",
        "    for rec in store:\n",
        "        rec[\"doc_type\"] = classify_doc_type_llm(rec.get(\"text\", \"\"))\n",
        "\n",
        "# -------- 5) Filter Pages by Predicted doc_type (+ fallback) ----\n",
        "def _keyword_fallback_score(text: str, query: str) -> int:\n",
        "    base_terms = re.findall(r\"[a-zA-Z0-9']+\", (query or \"\").lower())\n",
        "    extra = []\n",
        "    if any(k in (query or \"\").lower() for k in [\"salary\", \"pay\"]):\n",
        "        extra += [\"net pay\", \"gross\", \"pay date\", \"earnings\"]\n",
        "    if any(k in (query or \"\").lower() for k in [\"loan\", \"mortgage\", \"fees\"]):\n",
        "        extra += [\"origination\", \"escrow\", \"title\", \"interest\", \"closing costs\"]\n",
        "    terms = set([t for t in base_terms if len(t) > 2] + extra)\n",
        "    tl = (text or \"\").lower()\n",
        "    return sum(tl.count(term) for term in terms)"
      ],
      "metadata": {
        "id": "9Lt1kIZSWF6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_query(store: List[Dict[str, Any]], query: str) -> Dict[str, Any]:\n",
        "    predicted = classify_query_llm(query)\n",
        "    candidates = [rec for rec in store if rec.get(\"doc_type\") == predicted]\n",
        "\n",
        "    if not candidates:\n",
        "        candidates = sorted(store, key=lambda r: _keyword_fallback_score(r.get(\"text\", \"\"), query), reverse=True)[:1]\n",
        "    else:\n",
        "        candidates = sorted(candidates, key=lambda r: _keyword_fallback_score(r.get(\"text\", \"\"), query), reverse=True)[:1]\n",
        "\n",
        "\n",
        "    # -------- 6) Return the Final Output (EXACT schema) ----------\n",
        "    # We use OrderedDict to keep key order matching the expected format.\n",
        "    md_list = []\n",
        "    for rec in candidates:   # <-- stays INSIDE this function\n",
        "        item = OrderedDict()\n",
        "        item[\"file_id\"] = rec[\"file_id\"]\n",
        "        item[\"user_id\"] = \"xyz\"\n",
        "        item[\"doc_type\"] = rec[\"doc_type\"] or \"unknown\"\n",
        "        item[\"year\"] = str(rec.get(\"year\") or \"\")\n",
        "        item[\"filename\"] = rec[\"filename\"]\n",
        "        item[\"page_number\"] = int(rec[\"page_number\"])\n",
        "        item[\"text\"] = (rec[\"text\"] or \"\").strip()\n",
        "        md_list.append(item)\n",
        "\n",
        "    output = OrderedDict()\n",
        "    output[\"query\"] = query\n",
        "    output[\"predicted_doc_type\"] = predicted\n",
        "    output[\"matched_documents\"] = md_list\n",
        "    return output"
      ],
      "metadata": {
        "id": "bU7HsBnmWL0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Build & run once (sample) ===\n",
        "store = build_pdf_metadata_store(FILES)\n",
        "assign_doc_types(store)\n",
        "query = \"What is my monthly salary?\"\n",
        "result = route_query(store, query)\n",
        "\n",
        "# Save exact-schema JSON (optional)\n",
        "with open(\"/content/routing_result_exact.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(result, f, indent=2)\n",
        "\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEUwb-dhWOHB",
        "outputId": "ebe8ccce-4432-4309-977f-b81f9ee95f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('query', 'What is my monthly salary?'),\n",
              "             ('predicted_doc_type', 'pay_stub'),\n",
              "             ('matched_documents',\n",
              "              [OrderedDict([('file_id',\n",
              "                             '55052b7e-063d-4ea5-a4e0-646b65862452'),\n",
              "                            ('user_id', 'xyz'),\n",
              "                            ('doc_type', 'unknown'),\n",
              "                            ('year', ''),\n",
              "                            ('filename', 'payslip-1752803610.pdf'),\n",
              "                            ('page_number', 1),\n",
              "                            ('text', '')])])])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}